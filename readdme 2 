# üîÆ CRYPTO ORACLE MEMECOIN DETECTOR V4.2
## Architecture Technique Compl√®te - Production Ready

---

## 1. VISION ET MISSION

### 1.1 Objectif Principal
Syst√®me de d√©tection et surveillance int√©gr√© des tokens Solana post-AMM √† fort potentiel, capable d'identifier et monitorer les tokens prometteurs tant en phase initiale qu'en r√©activation tardive, avec une pr√©cision pr√©dictive sup√©rieure √† 85%.

### 1.2 Capacit√©s Strat√©giques
- **D√©tection pr√©coce**: Identification des tokens √† fort potentiel d√®s leur migration AMM
- **Filtrage anti-wash trading**: D√©tection automatique des tokens avec volume artificiel et m√©triques manipul√©es
- **Intelligence smart money**: Analyse pond√©r√©e des mouvements et concentrations des wallets de confiance
- **Suivi adaptatif**: Monitoring √©volutif bas√© sur le comportement des wallets et m√©triques de march√©
- **Intelligence cumulative**: Syst√®me auto-apprenant bas√© sur l'historique des interactions
- **R√©activation tracking**: D√©tection des "late bloomers" jusqu'√† 30 jours apr√®s leur lancement
- **Filtrage anti-bruit**: Identification proactive des sch√©mas de manipulation et dump coordonn√©s

---

## 2. ARCHITECTURE SYST√àME OPTIMIS√âE

### 2.1 Vue d'Ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       D√âTECTION AVANC√âE ET MONITORING                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ               ‚îÇ                    ‚îÇ                ‚îÇ                   ‚îÇ
‚îÇ  GMGN GATEWAY ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ TOKEN ENGINE   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ SMART      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂ MEMORY OF     ‚îÇ
‚îÇ  + PAGINATION ‚îÇ     + WASH FILTER  ‚îÇ     WALLET     ‚îÇ     TRUST         ‚îÇ
‚îÇ               ‚îÇ                    ‚îÇ     ANALYZER   ‚îÇ     NETWORK       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ                 ‚îÇ                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ‚îÇ    ‚îÇ                 ‚îÇ   ‚îÇ               ‚îÇ   ‚îÇ               ‚îÇ
‚îÇ ALERT MANAGER ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚î§  X-SCORE ENGINE ‚îÇ‚óÄ‚îÄ‚îÄ‚î§ SIGNAL        ‚îÇ‚óÄ‚îÄ‚îÄ‚î§ ANTI-DUMP     ‚îÇ
‚îÇ               ‚îÇ    ‚îÇ  AM√âLIOR√â       ‚îÇ   ‚îÇ DETECTOR      ‚îÇ   ‚îÇ DETECTOR      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     SURVEILLANCE ET D√âTECTION TARDIVE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ               ‚îÇ                    ‚îÇ                ‚îÇ                   ‚îÇ
‚îÇ LIFECYCLE     ‚îÇ REACTIVATION       ‚îÇ SMART WALLET   ‚îÇ DASHBOARD &       ‚îÇ
‚îÇ MANAGER       ‚îÇ DETECTOR           ‚îÇ RETURN         ‚îÇ NOTIFICATIONS     ‚îÇ
‚îÇ ADAPTATIF     ‚îÇ                    ‚îÇ DETECTOR       ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Pipeline de Traitement Optimis√©

```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                ‚îÇ
                ‚îÇ  GMGN API      ‚îÇ
                ‚îÇ  (Pagination)  ‚îÇ
                ‚îÇ                ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                           ‚îÇ
‚îÇ           REDIS STREAMS & CONSUMER GROUPS                 ‚îÇ
‚îÇ                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ             ‚îÇ                ‚îÇ
        ‚ñº             ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SHORT-TERM   ‚îÇ ‚îÇ LONG-TERM    ‚îÇ ‚îÇ TIMESCALEDB      ‚îÇ
‚îÇ  HOT CACHE    ‚îÇ ‚îÇ WARM CACHE   ‚îÇ ‚îÇ STORAGE LAYER    ‚îÇ
‚îÇ  (Redis)      ‚îÇ ‚îÇ (Redis)      ‚îÇ ‚îÇ (PostgreSQL)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.3 Distribution des Responsabilit√©s

| Composant | Responsabilit√©s |
|-----------|-----------------|
| GMGN Gateway + Pagination | Interface API, gestion pagination compl√®te, rate limiting, caching, r√©silience |
| Token Engine + Wash Filter | Classification tokens, filtrage volume/mcap ratio, tracking lifecycle |
| Smart Wallet Analyzer | Profiling wallets, Smart Money detection, Sniper detection, Trust Network |
| Signal Detector | D√©tection patterns, clustering, Anti-Dump detection |
| X-Score Core Am√©lior√© | Scoring intelligent multi-crit√®res avec pond√©ration smart money et bonus sniper |
| Lifecycle Manager Adaptatif | Gestion √©tats tokens, TTL adaptatif, transitions |
| Reactivation Detector | Suivi tokens dormants, d√©tection renaissance |
| Smart Wallet Return Detector | Analyse retour wallets smart sur tokens dormants |
| Memory of Trust | Base de connaissances cumulative des interactions |

---

## 3. GESTION DU CYCLE DE VIE ADAPTATIF

### 3.1 √âtats de Lifecycle Complets

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ             ‚îÇ
                    ‚îÇ   CREATED   ‚îÇ
                    ‚îÇ             ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ             ‚îÇ
‚îÇ  COMPLETED  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  DISCOVERED  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  VALIDATED  ‚îÇ
‚îÇ             ‚îÇ     ‚îÇ              ‚îÇ     ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                ‚îÇ
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
                 ‚îÇ                ‚îÇ             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ                  ‚îÇ   ‚îÇ                   ‚îÇ    ‚îÇ
‚îÇ    SLEEP_MODE    ‚îÇ‚óÄ‚îÄ‚îÄ‚î§       HYPED      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ                  ‚îÇ   ‚îÇ                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                       ‚îÇ
       ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ     ‚îÇ                        ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  MONITORING_LIGHT      ‚îÇ
             ‚îÇ                        ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ                        ‚îÇ
             ‚îÇ     REACTIVATED        ‚îÇ
             ‚îÇ                        ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 D√©finition des √âtats

| √âtat | Description | TTL | Polling |
|------|-------------|-----|---------|
| COMPLETED | Token d√©tect√© migr√© en AMM | - | - |
| DISCOVERED | Premier scan effectu√© | 6h | 15min |
| VALIDATED | X-Score > 60, prometteur | 24h | 5min |
| HYPED | X-Score > 80, haute priorit√© | 48h | 1min |
| SLEEP_MODE | Activit√© ralentie | 30j | 1h |
| MONITORING_LIGHT | Potentiel de r√©activation | 30j | 15min |
| REACTIVATED | Regain d'activit√© | 48h | 1min |

### 3.3 Politique de Transition Intelligente

```python
def determine_next_state(token, metrics):
    """
    D√©termine l'√©tat suivant du token bas√© sur les m√©triques actuelles
    """
    current_state = token["lifecycle_state"]
    current_x_score = metrics["x_score"]
    volume_1h = metrics["volume_1h"]
    volume_growth = metrics["volume_growth_rate"]
    price_growth = metrics["price_change_1h"]
    smart_wallet_activity = metrics["smart_wallet_activity_score"]
    time_since_completion = (datetime.now() - token["completion_timestamp"]).total_seconds() / 86400  # en jours
    
    # Transitions bas√©es sur l'√©tat actuel
    if current_state == "DISCOVERED":
        if current_x_score >= 80:
            return "HYPED"
        elif current_x_score >= 60:
            return "VALIDATED"
        else:
            return "SLEEP_MODE"
    
    elif current_state == "VALIDATED":
        if current_x_score >= 80:
            return "HYPED"
        elif current_x_score < 50 and time_since_completion > 1:
            return "SLEEP_MODE"
        else:
            return "VALIDATED"  # maintien
    
    elif current_state == "HYPED":
        if current_x_score >= 75:
            return "HYPED"  # maintien
        elif current_x_score >= 60:
            return "VALIDATED"  # d√©gradation l√©g√®re
        else:
            return "SLEEP_MODE"  # fort ralentissement
    
    elif current_state == "SLEEP_MODE":
        # Crit√®res de r√©activation
        if (volume_1h > 50000 and volume_growth > 2.0) or smart_wallet_activity > 70:
            return "REACTIVATED"
        elif smart_wallet_activity > 40 or volume_growth > 1.5:
            return "MONITORING_LIGHT"
        else:
            return "SLEEP_MODE"  # maintien
    
    elif current_state == "MONITORING_LIGHT":
        if (volume_1h > 100000 and volume_growth > 2.0) or (price_growth > 0.3 and smart_wallet_activity > 60):
            return "REACTIVATED"
        elif volume_1h < 10000 and smart_wallet_activity < 20 and time_since_completion > 14:
            return "SLEEP_MODE"
        else:
            return "MONITORING_LIGHT"  # maintien
    
    elif current_state == "REACTIVATED":
        if current_x_score >= 80:
            return "HYPED"
        elif current_x_score >= 60:
            return "VALIDATED"
        else:
            return "MONITORING_LIGHT"
    
    return current_state  # fallback = maintien
```

### 3.4 M√©canisme TTL Adaptatif

```python
def calculate_token_ttl(token):
    """
    Calcule la dur√©e de vie r√©siduelle du token bas√©e sur son √©tat et son potentiel
    """
    base_ttl = {
        "DISCOVERED": 6 * 3600,       # 6 heures
        "VALIDATED": 24 * 3600,       # 24 heures
        "HYPED": 48 * 3600,           # 48 heures
        "SLEEP_MODE": 30 * 86400,     # 30 jours
        "MONITORING_LIGHT": 30 * 86400, # 30 jours
        "REACTIVATED": 48 * 3600      # 48 heures
    }
    
    state = token["lifecycle_state"]
    x_score = token["latest_x_score"] or 0
    historical_volume = token["historical_max_volume"] or 0
    time_factor = min(1.0, get_token_age_days(token) / 30.0)
    
    # Facteurs d'ajustement
    score_factor = 1.0 + (x_score / 100.0)  # 1.0 - 2.0
    volume_factor = 1.0 + min(1.0, historical_volume / 1000000.0)  # 1.0 - 2.0
    
    # TTL de base
    ttl = base_ttl.get(state, 24 * 3600)
    
    # Tokens √† fort historique ont un TTL plus long
    if state in ["SLEEP_MODE", "MONITORING_LIGHT"]:
        ttl = ttl * volume_factor
    
    # Tokens r√©cents √† haut score ont une extension de TTL
    if state in ["VALIDATED", "HYPED"] and x_score > 70:
        ttl = ttl * score_factor
    
    # R√©duction progressive avec l'√¢ge sauf pour les tokens √† tr√®s haut volume historique
    if state != "REACTIVATED" and historical_volume < 5000000:
        ttl = ttl * (1.0 - (time_factor * 0.5))
    
    return int(ttl)
```

---

## 4. PIPELINE DE D√âTECTION ET ANALYSE AM√âLIOR√â

### 4.1 Processus de D√©tection

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ
‚îÇ  EXTRACTION   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   FILTRAGE    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ENRICHISSEMENT‚îÇ
‚îÇ  PAGIN√âE      ‚îÇ    ‚îÇ  OPTIMIS√â     ‚îÇ    ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ
‚îÇ   X-SCORING   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚î§  ANTI-DUMP    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚î§   ANALYSE     ‚îÇ
‚îÇ   AM√âLIOR√â    ‚îÇ    ‚îÇ  VALIDATION   ‚îÇ    ‚îÇ  WALLET       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ
‚îÇ  CLASSIFICATION‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  NOTIFICATION ‚îÇ
‚îÇ               ‚îÇ    ‚îÇ               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Filtrage Multi-niveaux Optimis√©

```python
def token_qualifies_for_monitoring(token, metrics):
    """
    D√©termine si un token m√©rite d'√™tre monitor√© selon des crit√®res stricts am√©lior√©s
    """
    # Niveau 1: Filtres basiques
    if (metrics["market_cap_usd"] < 50000 or
        metrics["holder_count"] < 50):
        return False, "Failed basic filters"
    
    # Niveau 2: Qualit√© token
    if (metrics["creator_balance_rate"] > 0.20 or
        metrics["top_10_holder_rate"] > 0.70 or
        metrics["is_wash_trading"] == True):
        return False, "Failed quality filters"
    
    # NOUVEAU: Ratio volume/mcap - D√©tection wash trading
    if (metrics["volume_1h"] / max(1.0, metrics["market_cap_usd"])) > 0.5:
        return False, "Suspected wash trading (volume/mcap > 0.5)"
    
    # Niveau 3: Activit√© minimale
    if metrics["volume_1h"] < 5000:
        return False, "Insufficient volume"
    
    # Niveau 4: Structures wallet saines
    wallet_metrics = metrics["wallet_metrics"]
    if wallet_metrics:
        if (wallet_metrics["dex_bot_ratio"] > 0.40 or
            wallet_metrics["fresh_wallet_ratio"] > 0.70):
            return False, "Suspicious wallet structure"
    
    # Niveau 5: Validation anti-dump
    if metrics.get("anti_dump_detected", False) and metrics.get("anti_dump_severity", 0) > 60:
        return False, "Anti-dump pattern detected"
    
    return True, "Passed all filters"
```

### 4.3 Analyse Wallet Optimis√©e avec Pagination

```python
def analyze_token_wallets(token_address, memory_of_trust):
    """
    Analyse compl√®te des wallets pour un token avec pagination compl√®te
    """
    # R√©cup√©rer donn√©es wallet avec pagination
    all_active_wallets = []
    next_pagination = None
    
    # Boucle de pagination pour r√©cup√©rer TOUS les wallets
    while True:
        active_wallets_page, next_pagination = fetch_token_active_wallets(
            token_address, 
            pagination_token=next_pagination
        )
        
        all_active_wallets.extend(active_wallets_page)
        
        # Si plus de r√©sultats √† paginer, sortir de la boucle
        if not next_pagination:
            break
    
    stats = {
        "token_address": token_address,
        "timestamp": datetime.now(),
        "total_wallets": len(all_active_wallets),
        "wallet_categories": {
            "smart": 0,
            "trusted": 0,
            "fresh": 0,
            "bot": 0,
            "sniper": 0,
            "bluechip": 0,
            "bundler": 0
        },
        "trust_metrics": {
            "avg_trust_score": 0,
            "smart_money_ratio": 0,
            "early_trusted_ratio": 0
        },
        "trade_patterns": {
            "buy_orders": 0,
            "sell_orders": 0,
            "buy_sell_ratio": 0,
            "avg_hold_time": 0
        }
    }
    
    # Analyser chaque wallet
    wallet_details = []
    trust_scores = []
    
    for wallet in all_active_wallets:
        # R√©cup√©rer profil wallet
        profile = get_wallet_profile(wallet["address"])
        
        # Obtenir trust score
        trust_score = memory_of_trust.get_wallet_trust_score(wallet["address"])
        trust_scores.append(trust_score)
        
        # Cat√©goriser wallet
        categories = categorize_wallet(wallet, profile, trust_score)
        for category in categories:
            stats["wallet_categories"][category] += 1
        
        # Analyser transactions
        transactions = get_wallet_token_transactions(wallet["address"], token_address)
        
        # Type d'ordre (buy/sell)
        buy_count = sum(1 for tx in transactions if tx["action_type"] == "buy")
        sell_count = sum(1 for tx in transactions if tx["action_type"] == "sell")
        
        stats["trade_patterns"]["buy_orders"] += buy_count
        stats["trade_patterns"]["sell_orders"] += sell_count
        
        # D√©tails wallet
        wallet_details.append({
            "address": wallet["address"],
            "trust_score": trust_score,
            "categories": categories,
            "entry_rank": wallet.get("entry_rank"),
            "entry_time": wallet.get("first_transaction_timestamp"),
            "volume": wallet.get("total_volume"),
            "buys": buy_count,
            "sells": sell_count
        })
    
    # Calculer m√©triques globales
    if trust_scores:
        stats["trust_metrics"]["avg_trust_score"] = sum(trust_scores) / len(trust_scores)
        stats["trust_metrics"]["smart_money_ratio"] = stats["wallet_categories"]["smart"] / max(1, stats["total_wallets"])
    
    if stats["trade_patterns"]["sell_orders"] > 0:
        stats["trade_patterns"]["buy_sell_ratio"] = stats["trade_patterns"]["buy_orders"] / stats["trade_patterns"]["sell_orders"]
    
    # D√©tection early trusted
    early_wallets = sorted(wallet_details, key=lambda w: w.get("entry_rank", float('inf')))[:10]
    stats["trust_metrics"]["early_trusted_ratio"] = len([w for w in early_wallets if w["trust_score"] > 70]) / max(1, len(early_wallets))
    
    # NOUVEAU: D√©tection wallets sniper
    stats["sniper_count"] = stats["wallet_categories"]["sniper"]
    stats["sniper_ratio"] = stats["sniper_count"] / max(1, stats["total_wallets"])
    
    # Stocker d√©tails pour r√©f√©rence
    stats["wallet_details"] = wallet_details
    
    return stats
```

### 4.4 X-Score Engine Am√©lior√© avec Pond√©ration Smart Money

```python
def calculate_x_score(token, metrics, wallet_analysis, memory_of_trust):
    """
    Calcule le X-Score complet am√©lior√© avec facteurs smart money et sniper
    """
    components = {}
    
    # 1. Qualit√© Token (20%)
    token_quality = calculate_token_quality(token, metrics)
    components["token_quality"] = token_quality * 0.20
    
    # 2. Wallet Quality (25%)
    wallet_quality = calculate_wallet_quality(wallet_analysis)
    components["wallet_quality"] = wallet_quality * 0.25
    
    # 3. Memory of Trust (20%)
    trust_factor = calculate_trust_factor(token, wallet_analysis, memory_of_trust)
    components["trust_factor"] = trust_factor * 0.20
    
    # 4. Market Dynamics (15%)
    market_factor = calculate_market_dynamics(metrics)
    components["market_factor"] = market_factor * 0.15
    
    # 5. Temporal Patterns (10%)
    temporal_factor = calculate_temporal_patterns(token, metrics)
    components["temporal_factor"] = temporal_factor * 0.10
    
    # 6. Reactivation Boost (10%)
    reactivation_factor = calculate_reactivation_factor(token, metrics)
    components["reactivation_factor"] = reactivation_factor * 0.10
    
    # NOUVEAU: Bonus Sniper Wallets
    sniper_count = wallet_analysis.get("sniper_count", 0) 
    sniper_bonus = 5 * min(1.0, sniper_count / 3)
    components["sniper_bonus"] = sniper_bonus
    
    # NOUVEAU: Pond√©ration price_change √ó smart_money_ratio
    price_change = metrics.get("price_change_1h", 0)
    smart_money_ratio = wallet_analysis.get("trust_metrics", {}).get("smart_money_ratio", 0)
    
    # Boost significatif si le prix augmente ET que les smart money sont pr√©sents
    price_smart_boost = price_change * smart_money_ratio * 10
    components["price_smart_boost"] = price_smart_boost
    
    # Score de base (somme des composantes)
    base_score = sum(components.values())
    
    # Anti-Dump Check
    anti_dump = check_anti_dump_pattern(token, wallet_analysis)
    
    # Application p√©nalit√© dump si d√©tect√©
    final_score = base_score
    if anti_dump["detected"]:
        # P√©nalit√© proportionnelle √† la s√©v√©rit√©
        dump_penalty = min(0.90, anti_dump["severity"] / 100)
        final_score = base_score * (1.0 - dump_penalty)
        components["anti_dump_penalty"] = -base_score * dump_penalty
    
    # Range final 0-100
    final_score = max(0, min(100, final_score))
    
    return {
        "token_address": token["address"],
        "x_score": final_score,
        "base_score": base_score,
        "components": components,
        "anti_dump": anti_dump,
        "calculated_at": datetime.now()
    }
```

---

## 5. MEMORY OF TRUST NETWORK

### 5.1 Structure de Donn√©es

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     MEMORY OF TRUST                        ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  WALLET       ‚îÇ  ‚îÇ INTERACTION   ‚îÇ  ‚îÇ TOKEN         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  PROFILES     ‚îÇ  ‚îÇ HISTORY       ‚îÇ  ‚îÇ ASSOCIATIONS  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ          ‚îÇ                 ‚îÇ                   ‚îÇ           ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                            ‚îÇ                               ‚îÇ
‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                 ‚îÇ                    ‚îÇ                     ‚îÇ
‚îÇ                 ‚îÇ    TRUST GRAPH     ‚îÇ                     ‚îÇ
‚îÇ                 ‚îÇ                    ‚îÇ                     ‚îÇ
‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Impl√©mentation Robuste

```python
class MemoryOfTrust:
    def __init__(self, db_connection, cache_client):
        self.db = db_connection
        self.cache = cache_client
        self.trust_graph = self._load_trust_graph()
    
    def record_wallet_interaction(self, wallet_address, token_address, action_type, amount, price, success=None):
        """
        Enregistre une nouvelle interaction wallet-token
        """
        # Horodatage pr√©cis
        timestamp = datetime.now()
        
        # D√©terminer succ√®s si non fourni (bas√© sur profit)
        if success is None and action_type == "sell":
            success = self._calculate_profit(wallet_address, token_address, price) > 0
        
        # Cr√©er entr√©e historique
        interaction = {
            "wallet_address": wallet_address,
            "token_address": token_address,
            "action_type": action_type,
            "amount_sol": amount,
            "price": price,
            "timestamp": timestamp,
            "success": success
        }
        
        # Stocker en DB
        self.db.store_wallet_interaction(interaction)
        
        # Mettre √† jour compte d'interactions
        self._update_interaction_count(wallet_address, token_address, action_type)
        
        # Invalidation cache selective
        self._invalidate_related_caches(wallet_address, token_address)
        
        # Mise √† jour asynchrone des scores
        self._schedule_trust_update(wallet_address)
        
        return True
    
    def get_wallet_trust_score(self, wallet_address):
        """
        R√©cup√®re le trust score d'un wallet (avec cache)
        """
        # V√©rifier cache
        cache_key = f"trust:wallet:{wallet_address}"
        cached = self.cache.get(cache_key)
        if cached is not None:
            return cached
        
        # R√©cup√©rer score stock√©
        stored_score = self.db.get_wallet_trust_score(wallet_address)
        if stored_score and stored_score["last_calculated_at"] > datetime.now() - timedelta(hours=24):
            # Mettre en cache pour 1h
            self.cache.set(cache_key, stored_score["trust_score"], 3600)
            return stored_score["trust_score"]
        
        # Recalculer si ancien ou inexistant
        trust_score = self._calculate_wallet_trust_score(wallet_address)
        
        # Mettre en cache
        self.cache.set(cache_key, trust_score, 3600)
        
        return trust_score
    
    def get_token_trust_metrics(self, token_address):
        """
        R√©cup√®re les m√©triques de confiance pour un token
        """
        # V√©rifier cache
        cache_key = f"trust:token:{token_address}"
        cached = self.cache.get(cache_key)
        if cached is not None:
            return cached
        
        # R√©cup√©rer wallets actifs sur ce token (avec pagination compl√®te)
        active_wallets = self._get_all_token_active_wallets(token_address)
        
        # Calculer m√©triques
        metrics = {
            "token_address": token_address,
            "active_wallets": len(active_wallets),
            "trusted_wallets": 0,
            "avg_trust_score": 0,
            "trust_score_distribution": {
                "high": 0,    # >80
                "medium": 0,  # 50-80
                "low": 0      # <50
            }
        }
        
        # Calculer scores pour chaque wallet
        if active_wallets:
            total_score = 0
            for wallet in active_wallets:
                trust_score = self.get_wallet_trust_score(wallet["address"])
                total_score += trust_score
                
                if trust_score >= 80:
                    metrics["trust_score_distribution"]["high"] += 1
                elif trust_score >= 50:
                    metrics["trust_score_distribution"]["medium"] += 1
                else:
                    metrics["trust_score_distribution"]["low"] += 1
                
                if trust_score >= 70:
                    metrics["trusted_wallets"] += 1
            
            metrics["avg_trust_score"] = total_score / len(active_wallets)
        
        # Calculer early trust ratio
        early_wallets = self._get_early_wallets(token_address, limit=10)
        if early_wallets:
            early_trusted = sum(1 for w in early_wallets if self.get_wallet_trust_score(w["address"]) >= 70)
            metrics["early_trust_ratio"] = early_trusted / len(early_wallets)
        else:
            metrics["early_trust_ratio"] = 0
        
        # Mettre en cache pour 15min
        self.cache.set(cache_key, metrics, 900)
        
        return metrics
        
    def _get_all_token_active_wallets(self, token_address):
        """
        R√©cup√®re tous les wallets actifs pour un token avec pagination compl√®te
        """
        all_wallets = []
        next_token = None
        
        while True:
            wallets_page, next_token = self.db.get_token_active_wallets(token_address, pagination_token=next_token)
            all_wallets.extend(wallets_page)
            
            if not next_token:
                break
        
        return all_wallets
    
    # Autres m√©thodes omises pour concision
```

### 5.3 Routines de Maintenance

```python
def maintain_memory_of_trust(memory, db):
    """
    Routine de maintenance p√©riodique du Memory of Trust
    """
    # 1. Recalculer scores des wallets les plus actifs
    active_wallets = db.get_most_active_wallets(days=7, limit=1000)
    for wallet in active_wallets:
        memory.get_wallet_trust_score(wallet["address"])  # Trigger recalcul
    
    # 2. Nettoyer les caches obsol√®tes
    memory.clean_obsolete_caches()
    
    # 3. Reg√©n√©rer le Trust Graph
    memory.rebuild_trust_graph()
    
    # 4. Mettre √† jour les proximit√©s wallet-wallet
    memory.update_wallet_similarities()
    
    # 5. Archiver les anciennes interactions (>90 jours)
    db.archive_old_interactions(days=90)
    
    # 6. Optimiser les indexes de la base
    db.optimize_indexes()
    
    # 7. G√©n√©rer m√©triques syst√®me
    stats = memory.generate_system_metrics()
    
    return stats
```

---

## 6. ANTI-DUMP DETECTION SYSTEM

### 6.1 Anti-Dump Pattern Detector

```python
def check_anti_dump_pattern(token, wallet_analysis):
    """
    Recherche des patterns de dump coordonn√©s
    """
    # R√©cup√©rer transactions r√©centes (24h)
    transactions = get_token_recent_transactions(token["address"], hours=24)
    if not transactions:
        return {"detected": False, "severity": 0, "clusters": []}
    
    # Filtrer ventes uniquement
    sell_transactions = [tx for tx in transactions if tx["action_type"] == "sell"]
    
    # Si peu de ventes, pas de pattern
    if len(sell_transactions) < 5:
        return {"detected": False, "severity": 0, "clusters": []}
    
    # Trier par timestamp
    sell_transactions.sort(key=lambda tx: tx["timestamp"])
    
    # D√©tection clusters temporels (ventes rapproch√©es)
    clusters = []
    current_cluster = []
    for i, tx in enumerate(sell_transactions):
        if not current_cluster:
            current_cluster.append(tx)
            continue
        
        last_tx = current_cluster[-1]
        time_diff = (tx["timestamp"] - last_tx["timestamp"]).total_seconds()
        
        # Si vente dans fen√™tre 5min, ajouter au cluster
        if time_diff <= 300:  # 5 minutes
            current_cluster.append(tx)
        else:
            # Enregistrer cluster si significatif (3+ ventes)
            if len(current_cluster) >= 3:
                clusters.append(list(current_cluster))
            current_cluster = [tx]
    
    # Ajouter dernier cluster si significatif
    if len(current_cluster) >= 3:
        clusters.append(current_cluster)
    
    # Si pas de clusters significatifs
    if not clusters:
        return {"detected": False, "severity": 0, "clusters": []}
    
    # Analyser chaque cluster
    analyzed_clusters = []
    highest_severity = 0
    
    for cluster in clusters:
        # Extraire wallets vendeurs
        wallets = [tx["wallet_address"] for tx in cluster]
        unique_wallets = set(wallets)
        
        # Calculer volume total vendu
        total_volume = sum(tx["amount_sol"] for tx in cluster)
        
        # V√©rifier si wallets smart sont impliqu√©s
        wallet_details = wallet_analysis.get("wallet_details", [])
        smart_wallets = [w for w in wallet_details if "smart" in w.get("categories", [])]
        smart_addresses = {w["address"] for w in smart_wallets}
        
        smart_sellers = smart_addresses.intersection(unique_wallets)
        smart_seller_count = len(smart_sellers)
        
        # Calculer gravit√© du cluster
        if smart_seller_count > 0:
            # Plus grave si wallets smart impliqu√©s
            severity = min(100, (smart_seller_count * 20) + (total_volume / 100))
        else:
            # Moins grave si wallets non smart
            severity = min(60, (len(unique_wallets) * 10) + (total_volume / 200))
        
        # Marquer le cluster
        cluster_info = {
            "timestamp_start": cluster[0]["timestamp"],
            "timestamp_end": cluster[-1]["timestamp"],
            "duration_seconds": (cluster[-1]["timestamp"] - cluster[0]["timestamp"]).total_seconds(),
            "transaction_count": len(cluster),
            "unique_wallets": len(unique_wallets),
            "smart_wallets": smart_seller_count,
            "total_volume": total_volume,
            "severity": severity
        }
        
        analyzed_clusters.append(cluster_info)
        highest_severity = max(highest_severity, severity)
    
    # R√©sultats finaux
    return {
        "detected": highest_severity >= 30,  # Seuil de d√©tection
        "severity": highest_severity,
        "clusters": analyzed_clusters
    }
```

### 6.2 Automatic Pattern Learning

```python
def train_anti_dump_detector(db, model_storage):
    """
    Entra√Æne le d√©tecteur anti-dump sur les donn√©es historiques
    """
    # R√©cup√©rer exemples historiques de dumps confirm√©s
    dump_examples = db.get_confirmed_dump_patterns()
    
    # R√©cup√©rer contre-exemples (non-dumps)
    non_dump_examples = db.get_confirmed_non_dump_patterns()
    
    # Pr√©parer features d'entra√Ænement
    X = []
    y = []
    
    # Extraire features des dumps
    for example in dump_examples:
        features = extract_dump_features(example)
        X.append(features)
        y.append(1)  # Dump = 1
    
    # Extraire features des non-dumps
    for example in non_dump_examples:
        features = extract_dump_features(example)
        X.append(features)
        y.append(0)  # Non-dump = 0
    
    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    
    # Entra√Æner mod√®le
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    
    # √âvaluer mod√®le
    accuracy = model.score(X_test, y_test)
    
    # M√©triques d√©taill√©es
    y_pred = model.predict(X_test)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # Importance des features
    feature_importance = model.feature_importances_
    
    # Sauvegarder mod√®le
    model_storage.save_model("anti_dump_detector", model)
    
    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "feature_importance": feature_importance,
        "model_version": datetime.now()
    }
```

---

## 7. REACTIVATION MONITORING SYSTEM

### 7.1 Architecture Dedicated Reactivation Detection

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  REACTIVATION DETECTOR                     ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ DORMANT TOKEN  ‚îÇ  ‚îÇ  CHANGE        ‚îÇ  ‚îÇ  SMART WALLET‚îÇ  ‚îÇ
‚îÇ  ‚îÇ TRACKER        ‚îÇ  ‚îÇ  DETECTOR      ‚îÇ  ‚îÇ  RETURN      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ  ‚îÇ  DETECTOR    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                   ‚îÇ                 ‚îÇ          ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ          ‚îÇ
‚îÇ                     ‚îÇ                           ‚îÇ          ‚îÇ
‚îÇ                     ‚ñº                           ‚ñº          ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ          ‚îÇ                         ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ          ‚îÇ   REACTIVATION          ‚îÇ  ‚îÇ   MEMORY OF     ‚îÇ  ‚îÇ
‚îÇ          ‚îÇ   SCORING ENGINE        ‚îÇ  ‚îÇ   TRUST BOOST   ‚îÇ  ‚îÇ
‚îÇ          ‚îÇ                         ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                     ‚îÇ                           ‚îÇ          ‚îÇ
‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                  ‚îÇ                         ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ                      ‚îÇ                        ‚îÇ            ‚îÇ
‚îÇ                      ‚îÇ  ALERT MANAGER         ‚îÇ            ‚îÇ
‚îÇ                      ‚îÇ                        ‚îÇ            ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 7.2 Dormant Token Scanner avec Pagination

```python
def scan_dormant_tokens():
    """
    Scanne les tokens dormants pour d√©tecter des signes de r√©activation
    """
    # R√©cup√©rer tokens en SLEEP_MODE ou MONITORING_LIGHT
    dormant_tokens = db.get_tokens_by_states(["SLEEP_MODE", "MONITORING_LIGHT"])
    
    reactivation_candidates = []
    
    for token in dormant_tokens:
        # R√©cup√©rer m√©triques r√©centes
        current_metrics = fetch_token_latest_metrics(token["address"])
        
        # R√©cup√©rer snapshot pr√©c√©dent pour comparaison
        previous_metrics = db.get_token_last_snapshot(token["address"])
        
        if not previous_metrics:
            continue
        
        # Calculer changements
        changes = calculate_metric_changes(current_metrics, previous_metrics)
        
        # V√©rifier retour de wallets smart
        smart_returns = detect_smart_wallet_returns(token["address"], memory_of_trust)
        
        # V√©rifier signes de r√©activation
        reactivation_score = calculate_reactivation_score(token, changes, smart_returns)
        
        # Si score suffisant, marquer comme candidat
        if reactivation_score >= 60:
            reactivation_candidates.append({
                "token_address": token["address"],
                "token_symbol": token["symbol"],
                "reactivation_score": reactivation_score,
                "changes": changes,
                "smart_returns": smart_returns,
                "current_metrics": current_metrics
            })
    
    return reactivation_candidates
```

### 7.3 Smart Money Return Detection

```python
def detect_smart_wallet_returns(token_address, memory_of_trust):
    """
    D√©tecte le retour de wallets smart sur un token dormant
    """
    # R√©cup√©rer transactions r√©centes (48h)
    recent_transactions = get_token_recent_transactions(token_address, hours=48)
    
    if not recent_transactions:
        return {"detected": False, "wallets": []}
    
    # Filtrer achats uniquement
    buy_transactions = [tx for tx in recent_transactions if tx["action_type"] == "buy"]
    
    # Extraire wallets acheteurs
    buyer_addresses = set(tx["wallet_address"] for tx in buy_transactions)
    
    # V√©rifier historique de ces wallets avec ce token
    smart_returns = []
    
    for address in buyer_addresses:
        # V√©rifier si wallet est smart
        trust_score = memory_of_trust.get_wallet_trust_score(address)
        
        if trust_score < 70:
            continue  # Ignorer wallets non smart
        
        # V√©rifier si wallet a un historique avec ce token
        history = db.get_wallet_token_history(address, token_address)
        
        # Si wallet a vendu et revient (r√©-achat)
        if history and any(tx["action_type"] == "sell" for tx in history):
            # Trouver derni√®re vente
            last_sell = max((tx for tx in history if tx["action_type"] == "sell"), 
                            key=lambda tx: tx["timestamp"])
            
            # Trouver premier achat r√©cent
            first_recent_buy = min((tx for tx in buy_transactions if tx["wallet_address"] == address), 
                                   key=lambda tx: tx["timestamp"])
            
            # Si vente avant achat r√©cent (retour confirm√©)
            if last_sell["timestamp"] < first_recent_buy["timestamp"]:
                smart_returns.append({
                    "wallet_address": address,
                    "trust_score": trust_score,
                    "last_sell_timestamp": last_sell["timestamp"],
                    "return_timestamp": first_recent_buy["timestamp"],
                    "dormant_period_hours": (first_recent_buy["timestamp"] - last_sell["timestamp"]).total_seconds() / 3600,
                    "return_amount": first_recent_buy["amount_sol"]
                })
    
    # Si retours significatifs d√©tect√©s
    return {
        "detected": len(smart_returns) >= 2,  # Au moins 2 retours
        "wallets": smart_returns,
        "total_returning": len(smart_returns),
        "avg_trust_score": sum(w["trust_score"] for w in smart_returns) / max(1, len(smart_returns)),
        "total_return_volume": sum(w["return_amount"] for w in smart_returns)
    }
```

### 7.4 Reactivation Scoring

```python
def calculate_reactivation_score(token, changes, smart_returns=None):
    """
    Calcule un score de r√©activation bas√© sur les changements de m√©triques
    et le retour √©ventuel de wallets smart
    """
    # Facteurs de r√©activation
    volume_factor = min(1.0, changes.get("volume_1h_change", 0) / 5.0)  # 5x max
    price_factor = min(1.0, changes.get("price_change", 0) / 0.3)  # +30% max
    holders_factor = min(1.0, changes.get("holder_growth", 0) / 0.1)  # +10% max
    
    # Base score from metrics
    base_score = (
        volume_factor * 0.5 +
        price_factor * 0.3 +
        holders_factor * 0.2
    ) * 100
    
    # Bonus pour smart wallet returns
    smart_wallet_bonus = 0
    if smart_returns and smart_returns["detected"]:
        # Bonus proportionnel au nombre de wallets qui reviennent
        return_count_factor = min(1.0, smart_returns["total_returning"] / 5)  # Max pour 5 wallets
        
        # Bonus proportionnel √† la qualit√© des wallets
        trust_factor = smart_returns["avg_trust_score"] / 100
        
        # Bonus proportionnel au volume de retour
        volume_factor = min(1.0, smart_returns["total_return_volume"] / 500)  # Max pour 500 SOL
        
        # Calcul bonus final
        smart_wallet_bonus = (
            return_count_factor * 0.5 +
            trust_factor * 0.3 +
            volume_factor * 0.2
        ) * 30  # Max 30 points bonus
    
    # Score final
    reactivation_score = base_score + smart_wallet_bonus
    
    # Limiter √† 0-100
    return max(0, min(100, reactivation_score))
```

---

## 8. INFRASTRUCTURE TECHNIQUE

### 8.1 Stack Technologique

| Composant | Technologie | Justification |
|-----------|-------------|---------------|
| Core Services | Go | Performance, concurrence, faible empreinte m√©moire |
| Wallet Intelligence | Python + Pandas + NetworkX | Analyse donn√©es, graphes, ML |
| Database | PostgreSQL + TimescaleDB | Time-series, JSONB, indexation avanc√©e |
| Message Broker | Redis Streams + Consumer Groups | Fiabilit√©, scaling, idempotence |
| Cache | Redis | Performance, structures de donn√©es avanc√©es |
| API Gateway | Go (Fiber) | Efficacit√©, middleware support |
| Monitoring | Prometheus + Grafana | Visualisation temps r√©el, alertes |
| Deployment | Docker + Docker Compose | Portabilit√©, orchestration simple |

### 8.2 Architecture Backend

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   API GATEWAY LAYER                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       ‚îÇ       ‚îÇ                       ‚îÇ
‚îÇ  PUBLIC API ENDPOINTS ‚îÇ       ‚îÇ   ADMIN DASHBOARD    ‚îÇ
‚îÇ                       ‚îÇ       ‚îÇ                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                               ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   SERVICE LAYER                           ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ TOKEN       ‚îÇ   ‚îÇ WALLET      ‚îÇ   ‚îÇ ANALYSIS    ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ SERVICE     ‚îÇ   ‚îÇ SERVICE     ‚îÇ   ‚îÇ SERVICE     ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   DATA LAYER                              ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ REDIS       ‚îÇ   ‚îÇ POSTGRESQL  ‚îÇ   ‚îÇ TIMESCALEDB ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ STREAMS     ‚îÇ   ‚îÇ STORAGE     ‚îÇ   ‚îÇ METRICS     ‚îÇ     ‚îÇ
‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ   ‚îÇ             ‚îÇ     ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 8.3 Redis Consumer Groups Pipeline

```go
// Redis Consumer Groups Configuration
type ConsumerConfig struct {
    RedisURL        string
    StreamName      string
    GroupName       string
    ConsumerName    string
    BatchSize       int
    PollingInterval time.Duration
    MaxRetries      int
    RetryDelay      time.Duration
    DLQStream       string
}

// Consumer Group Worker
type ConsumerGroupWorker struct {
    config        ConsumerConfig
    redisClient   *redis.Client
    messageHandler MessageHandler
    stopCh        chan struct{}
    wg            sync.WaitGroup
    logger        *zap.Logger
}

// Initialisation Worker
func NewConsumerGroupWorker(config ConsumerConfig, handler MessageHandler) (*ConsumerGroupWorker, error) {
    // Valider configuration
    if config.StreamName == "" || config.GroupName == "" {
        return nil, errors.New("stream name and group name must be provided")
    }
    
    // Connexion Redis
    redisOpts, err := redis.ParseURL(config.RedisURL)
    if err != nil {
        return nil, fmt.Errorf("invalid Redis URL: %w", err)
    }
    
    redisClient := redis.NewClient(redisOpts)
    
    // Logger
    logger, _ := zap.NewProduction()
    
    worker := &ConsumerGroupWorker{
        config:        config,
        redisClient:   redisClient,
        messageHandler: handler,
        stopCh:        make(chan struct{}),
        logger:        logger,
    }
    
    return worker, nil
}

// D√©marrage Worker
func (w *ConsumerGroupWorker) Start() error {
    // Cr√©er consumer group si n'existe pas
    err := w.createConsumerGroupIfNotExists()
    if err != nil && !strings.Contains(err.Error(), "BUSYGROUP") {
        return fmt.Errorf("failed to create consumer group: %w", err)
    }
    
    w.logger.Info("Starting consumer group worker",
        zap.String("stream", w.config.StreamName),
        zap.String("group", w.config.GroupName),
        zap.String("consumer", w.config.ConsumerName))
    
    w.wg.Add(1)
    go func() {
        defer w.wg.Done()
        w.processMessages()
    }()
    
    // D√©marrer processus de gestion des messages en √©chec
    w.wg.Add(1)
    go func() {
        defer w.wg.Done()
        w.retryPendingMessages()
    }()
    
    return nil
}

// Traitement des messages
func (w *ConsumerGroupWorker) processMessages() {
    for {
        select {
        case <-w.stopCh:
            w.logger.Info("Stopping message processing")
            return
        default:
            // Lire messages du stream
            messages, err := w.redisClient.XReadGroup(&redis.XReadGroupArgs{
                Group:    w.config.GroupName,
                Consumer: w.config.ConsumerName,
                Streams:  []string{w.config.StreamName, ">"},
                Count:    int64(w.config.BatchSize),
                Block:    w.config.PollingInterval,
            }).Result()
            
            if err != nil {
                if err != redis.Nil {
                    w.logger.Error("Failed to read from stream",
                        zap.Error(err),
                        zap.String("stream", w.config.StreamName))
                    time.Sleep(w.config.RetryDelay)
                }
                continue
            }
            
            // Traiter les messages
            for _, stream := range messages {
                for _, message := range stream.Messages {
                    w.processMessage(message)
                }
            }
        }
    }
}

// Traitement individuel des messages
func (w *ConsumerGroupWorker) processMessage(message redis.XMessage) {
    w.logger.Debug("Processing message", 
        zap.String("id", message.ID),
        zap.Any("values", message.Values))
    
    // Convertir message
    parsedMessage, err := parseMessage(message.Values)
    if err != nil {
        w.logger.Error("Failed to parse message", 
            zap.Error(err), 
            zap.String("id", message.ID))
        
        // Stocker en DLQ et ack
        w.moveToDeadLetterQueue(message)
        return
    }
    
    // Traiter avec handler
    err = w.messageHandler(parsedMessage)
    
    if err != nil {
        w.logger.Error("Failed to process message", 
            zap.Error(err), 
            zap.String("id", message.ID))
        
        // Ne pas ack - sera retry automatiquement
        return
    }
    
    // Acknowledger si succ√®s
    err = w.redisClient.XAck(w.config.StreamName, w.config.GroupName, message.ID).Err()
    if err != nil {
        w.logger.Error("Failed to acknowledge message", 
            zap.Error(err), 
            zap.String("id", message.ID))
    }
}

// Reprise des messages en √©chec
func (w *ConsumerGroupWorker) retryPendingMessages() {
    ticker := time.NewTicker(w.config.RetryDelay)
    defer ticker.Stop()
    
    for {
        select {
        case <-w.stopCh:
            w.logger.Info("Stopping pending message retry")
            return
        case <-ticker.C:
            // R√©cup√©rer messages en attente
            pendingMessages, err := w.redisClient.XPendingExt(&redis.XPendingExtArgs{
                Stream:   w.config.StreamName,
                Group:    w.config.GroupName,
                Start:    "-",
                End:      "+",
                Count:    int64(w.config.BatchSize),
                Consumer: w.config.ConsumerName,
            }).Result()
            
            if err != nil {
                w.logger.Error("Failed to get pending messages", zap.Error(err))
                continue
            }
            
            for _, pending := range pendingMessages {
                // V√©rifier d√©passement retries
                if pending.RetryCount > int64(w.config.MaxRetries) {
                    w.logger.Warn("Message exceeded max retries, moving to DLQ", 
                        zap.String("id", pending.ID),
                        zap.Int64("retryCount", pending.RetryCount))
                    
                    // R√©cup√©rer message
                    messages, err := w.redisClient.XRange(w.config.StreamName, pending.ID, pending.ID).Result()
                    if err != nil || len(messages) == 0 {
                        w.logger.Error("Failed to retrieve pending message", zap.Error(err))
                        continue
                    }
                    
                    // D√©placer en DLQ
                    w.moveToDeadLetterQueue(messages[0])
                    continue
                }
                
                // R√©clamer message pour retry
                err := w.redisClient.XClaim(&redis.XClaimArgs{
                    Stream:   w.config.StreamName,
                    Group:    w.config.GroupName,
                    Consumer: w.config.ConsumerName,
                    MinIdle:  w.config.RetryDelay,
                    Messages: []string{pending.ID},
                }).Err()
                
                if err != nil {
                    w.logger.Error("Failed to claim pending message", 
                        zap.Error(err), 
                        zap.String("id", pending.ID))
                    continue
                }
                
                // R√©cup√©rer le message
                messages, err := w.redisClient.XRange(w.config.StreamName, pending.ID, pending.ID).Result()
                if err != nil || len(messages) == 0 {
                    w.logger.Error("Failed to retrieve claimed message", zap.Error(err))
                    continue
                }
                
                // Retraiter
                w.processMessage(messages[0])
            }
        }
    }
}
```

### 8.4 High-Performance Token Metrics Store

```sql
-- Hypertable pour m√©triques token haute-performance
CREATE TABLE token_metrics (
    token_address TEXT NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    price_sol NUMERIC,
    price_usd NUMERIC,
    market_cap_usd NUMERIC,
    volume_1h NUMERIC,
    volume_24h NUMERIC,
    holder_count INTEGER,
    buy_count_1h INTEGER,
    sell_count_1h INTEGER,
    buy_sell_ratio NUMERIC GENERATED ALWAYS AS (
        CASE WHEN sell_count_1h > 0 THEN buy_count_1h::numeric / sell_count_1h ELSE NULL END
    ) STORED,
    price_change_1h NUMERIC,
    holder_growth_1h NUMERIC,
    wallet_metrics JSONB,
    x_score NUMERIC,
    lifecycle_state TEXT,
    -- Nouveaux champs pour optimisations
    volume_mcap_ratio NUMERIC GENERATED ALWAYS AS (
        CASE WHEN market_cap_usd > 0 THEN volume_1h::numeric / market_cap_usd ELSE NULL END
    ) STORED,
    smart_money_ratio NUMERIC,
    sniper_count INTEGER
);

-- Convertir en hypertable
SELECT create_hypertable('token_metrics', 'timestamp', chunk_time_interval => INTERVAL '1 hour');

-- Index pour requ√™tes efficaces
CREATE INDEX idx_token_metrics_token_time ON token_metrics(token_address, timestamp DESC);
CREATE INDEX idx_token_metrics_x_score ON token_metrics(x_score DESC, timestamp DESC);
CREATE INDEX idx_token_metrics_volume ON token_metrics(volume_1h DESC, timestamp DESC);
CREATE INDEX idx_token_metrics_volume_mcap_ratio ON token_metrics(volume_mcap_ratio ASC, timestamp DESC);

-- Compression automatique
ALTER TABLE token_metrics SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'token_address',
    timescaledb.compress_orderby = 'timestamp DESC'
);

-- Politique compression (donn√©es > 7 jours)
SELECT add_compression_policy('token_metrics', INTERVAL '7 days');

-- Vue mat√©rialis√©e pour analyse tendance
CREATE MATERIALIZED VIEW token_daily_summary AS
SELECT 
    token_address,
    DATE_TRUNC('day', timestamp) AS day,
    MAX(x_score) AS max_x_score,
    AVG(price_usd) AS avg_price,
    MAX(market_cap_usd) AS max_market_cap,
    SUM(volume_1h) AS total_volume,
    MAX(holder_count) AS max_holders,
    AVG(buy_sell_ratio) AS avg_buy_sell_ratio,
    AVG(volume_mcap_ratio) AS avg_volume_mcap_ratio,
    MAX(smart_money_ratio) AS max_smart_money_ratio,
    MAX(sniper_count) AS max_sniper_count
FROM token_metrics
GROUP BY token_address, DATE_TRUNC('day', timestamp);

-- Index sur vue
CREATE INDEX idx_token_daily_token ON token_daily_summary(token_address, day DESC);
CREATE INDEX idx_token_daily_volume ON token_daily_summary(total_volume DESC, day DESC);

-- Continuous aggregate pour analyses rapides sur donn√©es historiques
SELECT add_continuous_aggregate_policy('token_daily_summary',
    start_offset => INTERVAL '30 days',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');
```

### 8.5 Client GMGN Optimis√© avec Pagination

```go
// Client GMGN avec support complet de pagination
type GMGNClient struct {
    BaseURL        string
    APIKey         string
    HTTPClient     *http.Client
    RateLimitDelay time.Duration
    Logger         *zap.Logger
}

// Creates new GMGN API client
func NewGMGNClient(baseURL, apiKey string, rateLimitPerMinute int) *GMGNClient {
    delay := time.Minute / time.Duration(rateLimitPerMinute)
    if delay < 50*time.Millisecond {
        delay = 50 * time.Millisecond // Minimum 50ms entre requ√™tes
    }
    
    logger, _ := zap.NewProduction()
    
    return &GMGNClient{
        BaseURL:        baseURL,
        APIKey:         apiKey,
        HTTPClient:     &http.Client{Timeout: 10 * time.Second},
        RateLimitDelay: delay,
        Logger:         logger,
    }
}

// GetAllWalletHoldings r√©cup√®re tous les holdings d'un wallet avec pagination
func (c *GMGNClient) GetAllWalletHoldings(walletAddress string) ([]model.Holding, error) {
    var allHoldings []model.Holding
    nextToken := ""
    
    for {
        // Construire URL avec pagination
        url := fmt.Sprintf("%s/api/v1/wallet_holdings/sol/%s", c.BaseURL, walletAddress)
        if nextToken != "" {
            url = fmt.Sprintf("%s?next=%s", url, nextToken)
        }
        
        // Effectuer requ√™te
        response, err := c.makeRequest("GET", url, nil)
        if err != nil {
            return nil, fmt.Errorf("failed to get wallet holdings: %w", err)
        }
        
        // Parser r√©ponse
        var holdingsResponse model.WalletHoldingsResponse
        if err := json.Unmarshal(response, &holdingsResponse); err != nil {
            return nil, fmt.Errorf("failed to parse holdings response: %w", err)
        }
        
        // Ajouter holdings √† la liste compl√®te
        allHoldings = append(allHoldings, holdingsResponse.Data.Holdings...)
        
        // V√©rifier si plus de pages
        if holdingsResponse.Data.Next == "" {
            break
        }
        
        // Pr√©parer pour la prochaine page
        nextToken = holdingsResponse.Data.Next
        
        // Respecter rate limit
        time.Sleep(c.RateLimitDelay)
    }
    
    return allHoldings, nil
}

// GetAllTokenTraders r√©cup√®re tous les traders d'un token avec pagination
func (c *GMGNClient) GetAllTokenTraders(tokenAddress string) ([]model.Trader, error) {
    var allTraders []model.Trader
    nextToken := ""
    
    for {
        // Construire URL avec pagination
        url := fmt.Sprintf("%s/vas/api/v1/token_traders/sol/%s", c.BaseURL, tokenAddress)
        if nextToken != "" {
            url = fmt.Sprintf("%s?next=%s", url, nextToken)
        }
        
        // Effectuer requ√™te
        response, err := c.makeRequest("GET", url, nil)
        if err != nil {
            return nil, fmt.Errorf("failed to get token traders: %w", err)
        }
        
        // Parser r√©ponse
        var tradersResponse model.TokenTradersResponse
        if err := json.Unmarshal(response, &tradersResponse); err != nil {
            return nil, fmt.Errorf("failed to parse traders response: %w", err)
        }
        
        // Ajouter traders √† la liste compl√®te
        allTraders = append(allTraders, tradersResponse.Data.List...)
        
        // V√©rifier si plus de pages
        if tradersResponse.Data.Next == "" {
            break
        }
        
        // Pr√©parer pour la prochaine page
        nextToken = tradersResponse.Data.Next
        
        // Respecter rate limit
        time.Sleep(c.RateLimitDelay)
    }
    
    return allTraders, nil
}

// GetAllTokenTrades r√©cup√®re toutes les transactions d'un token avec pagination
func (c *GMGNClient) GetAllTokenTrades(tokenAddress string, limit int) ([]model.Trade, error) {
    var allTrades []model.Trade
    nextToken := ""
    
    // Limiter le nombre total de trades √† r√©cup√©rer
    maxTrades := limit
    if maxTrades <= 0 {
        maxTrades = 1000 // Valeur par d√©faut
    }
    
    for len(allTrades) < maxTrades {
        // Construire URL avec pagination
        url := fmt.Sprintf("%s/vas/api/v1/token_trades/sol/%s", c.BaseURL, tokenAddress)
        if nextToken != "" {
            url = fmt.Sprintf("%s?next=%s", url, nextToken)
        }
        
        // Effectuer requ√™te
        response, err := c.makeRequest("GET", url, nil)
        if err != nil {
            return nil, fmt.Errorf("failed to get token trades: %w", err)
        }
        
        // Parser r√©ponse
        var tradesResponse model.TokenTradesResponse
        if err := json.Unmarshal(response, &tradesResponse); err != nil {
            return nil, fmt.Errorf("failed to parse trades response: %w", err)
        }
        
        // Ajouter trades √† la liste compl√®te
        allTrades = append(allTrades, tradesResponse.Data.History...)
        
        // V√©rifier si plus de pages ou si on a atteint la limite
        if tradesResponse.Data.Next == "" || len(allTrades) >= maxTrades {
            break
        }
        
        // Pr√©parer pour la prochaine page
        nextToken = tradesResponse.Data.Next
        
        // Respecter rate limit
        time.Sleep(c.RateLimitDelay)
    }
    
    // Limiter au nombre exact demand√©
    if len(allTrades) > maxTrades {
        allTrades = allTrades[:maxTrades]
    }
    
    return allTrades, nil
}

// M√©thode utilitaire pour effectuer les requ√™tes HTTP
func (c *GMGNClient) makeRequest(method, url string, body io.Reader) ([]byte, error) {
    req, err := http.NewRequest(method, url, body)
    if err != nil {
        return nil, err
    }
    
    req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", c.APIKey))
    req.Header.Set("Content-Type", "application/json")
    
    resp, err := c.HTTPClient.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    // Gestion des erreurs HTTP
    if resp.StatusCode != http.StatusOK {
        respBody, _ := io.ReadAll(resp.Body)
        c.Logger.Error("GMGN API error",
            zap.Int("status", resp.StatusCode),
            zap.String("url", url),
            zap.String("response", string(respBody)))
        
        return nil, fmt.Errorf("API error: %d - %s", resp.StatusCode, string(respBody))
    }
    
    return io.ReadAll(resp.Body)
}
```

---

## 9. ROADMAP D'IMPL√âMENTATION

### Phase 1: Architecture & Infrastructure (Semaine 1)
- Setup repo et environment Docker
- GMGN Gateway avec caching adaptatif et pagination compl√®te
- Sch√©ma base de donn√©es (PostgreSQL + TimescaleDB)
- Redis Streams + Consumer Groups
- Pipeline core data processing

### Phase 2: Detection Engine Am√©lior√© (Semaine 2)
- Token Lifecycle Management
- Wallet Intelligence (avec support sniper)
- Filtrage optimis√© (ajout ratio volume/mcap)
- X-Score avec am√©liorations smart money
- Anti-Dump Detection
- Pipeline notifications

### Phase 3: Intelligence Avanc√©e (Semaine 3)
- Memory of Trust Core
- Trust Network
- Wallet clustering avanc√©
- X-Score enrichi final
- Dashboard v1

### Phase 4: Reactivation System (Semaine 4)
- Dormant Token Tracking
- Reactivation Detection
- Smart Wallet Return Analysis
- Long-term TTL Management
- Dashboard v2 avec Reactivation Alerts

### Phase 5: Optimisations & Production (Semaine 5)
- Performance tuning
- Scaling tests
- Security hardening
- API Gateway complete
- Documentation
- D√©ploiement production

### Phase 6: √âvolutions Post-Launch
- Auto-learning Memory of Trust
- Predictive Analytics
- Backtesting Framework
- API √©tendue
- Integration bots trading

---

## 10. M√âTRIQUES ET MONITORING

### 10.1 System Monitoring

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       SYSTEM HEALTH                        ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  API        ‚îÇ  ‚îÇ  REDIS      ‚îÇ  ‚îÇ  DATABASE   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  METRICS    ‚îÇ  ‚îÇ  METRICS    ‚îÇ  ‚îÇ  METRICS    ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     TOKEN INSIGHTS                         ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  ACTIVE     ‚îÇ  ‚îÇ  TOKEN      ‚îÇ  ‚îÇ  MEMORY OF  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  TOKENS     ‚îÇ  ‚îÇ  METRICS    ‚îÇ  ‚îÇ  TRUST      ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DETECTION PERFORMANCE                   ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  TOKEN      ‚îÇ  ‚îÇ  REACTIVATION‚îÇ  ‚îÇ  MISSED     ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  DETECTION  ‚îÇ  ‚îÇ  STATS      ‚îÇ  ‚îÇ  OPPORTUNITIES ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 10.2 Key Performance Indicators

| KPI | Description | Cible |
|-----|-------------|-------|
| Total Detection Rate | % tokens >$1M d√©tect√©s | >85% |
| Early Detection Rate | % tokens d√©tect√©s <30min apr√®s completion | >80% |
| Reactivation Detection | % tokens r√©activ√©s d√©tect√©s | >75% |
| False Positive Rate | % alertes sans traction significative | <10% |
| Memory of Trust Accuracy | Pr√©cision pr√©dictive wallets | >90% |
| Anti-Dump Detection | % patterns dump d√©tect√©s correctement | >85% |
| Smart Money Ratio | Pr√©sence smart wallets dans portfolio | >30% |

### 10.3 Alert System

Hi√©rarchie d'alertes intelligente:

| Niveau | D√©clencheur | Action |
|--------|-------------|--------|
| INFO | Token class√© VALIDATED | Log + UI Update |
| ALERT | Token class√© HYPED | Notification + Sound |
| URGENT | Token HYPED + Trust Factor √©lev√© | Push + SMS |
| CRITICAL | Multiple smart wallets entrent simultan√©ment | Push + SMS + Telegram |
| REACTIVATION | Token dormant r√©activ√© avec smart wallets | Notification sp√©ciale |
| DANGER | Anti-Dump d√©tect√© sur token suivi | Alerte rouge imm√©diate |

---

## 11. ARBORESCENCE DU CODE

```
crypto-oracle/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ oracle/                    # Point d'entr√©e principal
‚îÇ       ‚îú‚îÄ‚îÄ main.go                # Initialisation des composants 
‚îÇ       ‚îî‚îÄ‚îÄ startup.go             # S√©quence de d√©marrage et config
‚îÇ
‚îú‚îÄ‚îÄ internal/                      # Code priv√© de l'application
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # API Gateway
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.go              # Configuration serveur HTTP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware.go          # Middlewares API et rate limiting
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.go              # D√©finition des routes 
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handlers/              # Handlers des endpoints API
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ token/                     # Token Engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.go              # Core token engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lifecycle.go           # Gestion du cycle de vie et TTL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filtration/            # Syst√®me de filtrage am√©lior√©
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ filter.go          # Interface filtres
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quality_filter.go  # Filtres de qualit√©
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ volume_filter.go   # Filtre volume/market cap ratio
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ wallet_filter.go   # Filtres bas√©s sur wallets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detection.go           # D√©tection patterns et signaux 
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scoring/               # X-Score avec am√©liorations
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ core.go            # Calcul X-Score de base
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ components.go      # Composants individuels du score
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ boosters.go        # Boosters sp√©cifiques (sniper, smart money)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ wallet/                    # Wallet Intelligence
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intelligence.go        # Analyse et cat√©gorisation wallets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profiling.go           # Profiling comportements wallets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sniper_detection.go    # D√©tection wallets sniper am√©lior√©e
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smart_money.go         # Analyse et pond√©ration smart money
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ antidump.go            # D√©tection anti-dump patterns
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ memory/                    # Memory of Trust
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trust.go               # Core Memory of Trust
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ network.go             # Trust Network et graphes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage.go             # Persistance des donn√©es trust
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calculator.go          # Calcul scores de confiance
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ reactivation/              # Reactivation System
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detector.go            # D√©tection r√©activation tokens
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.go             # Mesures de r√©activation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smart_return.go        # D√©tection retour wallets smart
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scoring.go             # Scoring r√©activation
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ gateway/                   # GMGN Gateway
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.go              # Client API GMGN optimis√©
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.go               # Strat√©gies de cache 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pagination.go          # Gestion optimis√©e pagination
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoints/             # Wrapper endpoints GMGN
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                  # Stream Processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consumer.go            # Consumer Groups Redis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ producer.go            # Producer Stream Redis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/              # Handlers de messages sp√©cifiques
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workers.go             # Worker Pool management
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ alerting/                  # Alert System
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.go             # Gestion alertes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ channels/              # Multi-canal notifications
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ templates/             # Templates alertes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules.go               # R√®gles de d√©clenchement alertes
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ storage/                   # Persistence Layer
‚îÇ       ‚îú‚îÄ‚îÄ db/                    # Database layer
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ connection.go      # DB Connection/Pool management
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ migrations.go      # Gestion migrations
‚îÇ       ‚îú‚îÄ‚îÄ timescale/             # TimescaleDB pour time-series
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ repository.go      # Interface repository
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ token_metrics.go   # M√©triques temporelles tokens
‚îÇ       ‚îî‚îÄ‚îÄ cache/                 # Redis cache
‚îÇ           ‚îú‚îÄ‚îÄ client.go          # Client Redis
‚îÇ           ‚îî‚îÄ‚îÄ token_cache.go     # Cache donn√©es token
‚îÇ
‚îú‚îÄ‚îÄ pkg/                           # Code potentiellement r√©utilisable
‚îÇ   ‚îú‚îÄ‚îÄ utils/                     # Utilitaires g√©n√©riques
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/                # Gestion configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger/                # Logging system
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics/               # M√©triques performance
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ gmgn/                      # Client GMGN r√©utilisable
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.go              # Client GMGN de base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pagination.go          # Support pagination optimis√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.go              # Mod√®les donn√©es GMGN
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models/                    # Mod√®les de donn√©es
‚îÇ       ‚îú‚îÄ‚îÄ token.go               # Token models
‚îÇ       ‚îú‚îÄ‚îÄ wallet.go              # Wallet models
‚îÇ       ‚îî‚îÄ‚îÄ transaction.go         # Transaction models
‚îÇ
‚îú‚îÄ‚îÄ web/                           # Dashboard Web
‚îÇ   ‚îú‚îÄ‚îÄ assets/                    # Static assets
‚îÇ   ‚îú‚îÄ‚îÄ templates/                 # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.go               # Dashboard routing
‚îÇ
‚îú‚îÄ‚îÄ scripts/                       # Scripts utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ setup/                     # Scripts installation
‚îÇ   ‚îú‚îÄ‚îÄ db/                        # Scripts DB
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/                # Scripts monitoring
‚îÇ
‚îú‚îÄ‚îÄ deployments/                   # Configuration d√©ploiement
‚îÇ   ‚îú‚îÄ‚îÄ docker/                    # Configuration Docker
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/                # Configuration Kubernetes
‚îÇ   ‚îî‚îÄ‚îÄ configs/                   # Configs par environnement
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # Tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/                      # Tests unitaires
‚îÇ   ‚îú‚îÄ‚îÄ integration/               # Tests int√©gration
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Utils pour tests
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # Documentation API
‚îÇ   ‚îú‚îÄ‚îÄ architecture/              # Documentation architecture
‚îÇ   ‚îî‚îÄ‚îÄ operations/                # Documentation op√©rationnelle
‚îÇ
‚îú‚îÄ‚îÄ go.mod                         # Go module definition
‚îú‚îÄ‚îÄ go.sum                         # Go dependencies checksum
‚îî‚îÄ‚îÄ README.md                      # Documentation principale
```

---

**¬© 2025 Crypto Oracle Memecoin Detector v4.2**